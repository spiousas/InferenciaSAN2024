# *Potential outcomes* {#sec-pot-outcomes}

```{r}
#| echo: false

source("../R/_common.R")
```

## Presentación

Supongamos que quiero evaluar la efectividad de la aspirina para mitigar el dolor de cabeza. Me duele la cabeza y lo quiero es saber el efecto diferencial entre tomar y no tomar esa aspirina. Es decir, en el tiempo 0 estoy yo con dolor de cabeza y en el tiempo 1 debería haber dos versiones mías (como si una no fuera suficiente), la que tomó la aspirina y la que no. A cada una de ellas les tendría que preguntar cuánto les duele la cabeza, el *outcome* de mi comparación. No hace falta ser demasiado astuto para darse cuenta que esto es imposible ya que sólo nos será posible obsevar una de esas versiones mientras que la otra será un contrafáctico.

De esto vamos a hablar en este capítulo, utilizando la tradición de los *potential outcomes*. Estas ideas terminan de tomar forma en la versión que conocemos en las ciencias sociales en [@rubin1974estimating]

## *Potential outcomes*

Lo que nos proponen los *potential outcomes* es la definición del efecto causal como la comparación de dos estados en el mundo. En una versión del mundo, la "actual", me tomo una aspirina y a las dos horas registro la severidad de mi dolor de cabeza mientras que en la otra versión del mundo, la "contrafactual", no me la tomo y las dos horas registro la severidad del dolor. A partir de esto, la tradición de los *potential outcomes* define al efecto causal de tomar una aspirina en el dolor de cabeza como la diferencia entre esas dos mediciones.

Todo muy lindo, pero como ya estarán sospechando es imposible calcular un efecto que está expresado en función de un contrafactual, ya que este contrafactual no lo podemos observar. Pero no se preocupen que le vamos a encontrar la vuelta.

Empecemos con un poco de notación que nos va a ayudar a acomodar las ideas. Por simplicidad vamos a asumir una variable binaria para la asignación del grupo (por ejemplo, tratamiento y control). Esta variable vale $1$ si la unidad *i* recibe el tratamiento y $0$ si no. Cada unidad $i$ va a tener dos *potential outcomes*: $Y_i^1$ si la unidad recibió el tratamiento y $Y_i^0$ si no. Esto significa que una unidad experimental en el mismo momento del tiempo va a recibir y no recibir el tratamiento, o sea, alguno de estos va a ser contrafactual[^potential_outcomes-1].

[^potential_outcomes-1]: De ahí el nombre de *potential*, porque se trata de posibles estados del mundo. Un estado en el que la unidad $i$ recibe el tratamiento y uno en el que no.

Los *outcomes* observables difieren de los potenciales. Mientras que los potenciales son variables aleatorias hipotéticas, los observables son variables aleatorias factuales y medibles. Hay una ecuación que nos permite definir el *outcome* observable ($Y^i$) en función de los potenciales, se llama la *switching equation*:

$$
Y_i = D_i Y_i^1 + (1-D_i) Y_i^0 
$$ {#eq-switching}

Donde $D_i$ vale $1$ si la unidad *i* recibió el tratamiento (entonces $Y_i=Y_i^1$) y $0$ si no (entonces $Y_i=Y_i^0$). Vale la pena notar que $Y_i$, el *outcome* observable, no tiene ningún supraíndice ya que no es más potencial.

Usando esta notación definimos el efecto causal del tratamiento para una unidad $i$ como: 
$$
\delta_i = Y_i^1 - Y_i^0 
$$ {#eq-deltai}

Donde queda claro que para estimar el efecto causal de acuerdo a la tradición de los *potential outcomes* debemos conocer dos estados del mundo a los que es imposible acceder simultáneamente. Y aqui yace el problema funcamental de la inferencia causal:  Para calcular el efecto causal se requiere acceso a datos que siempre nos van a faltar (los contrafácticos)[@rubin1974estimating].

## Efecto promedio del tratamiento

Al igual que los *potential outcomes*, el efecto para la unidad $i$ ($\delta_i$) también es una variable aleatoria, y su esperanza es lo que vamos a llamar el efecto promedio del tratamiento (**ATE**[^ATE]). El **ATE** va a ser la magnitud de interés en nuestros experimentos, el efecto promedio de mi tratamiento. El mismo se define de la siguiente forma:

[^ATE]: Del inglés *Average treatment effect*.

$$
\begin{array}
_ATE &=& E[\delta_i] \\
&=& E[Y_i^1 - Y_i^0] \\
&=& E[Y_i^1] - E[Y_i^0] 
\end{array}
$${#eq-ATE}

Ahora vamos a definir el efecto promedio, pero para el grupo tratado (es decir, los participantes asignados al grupo tratamiento, con $D_i=1$):

$$
\begin{array}
_ATT &=& E[\delta_i|D_i=1] \\
&=& E[Y_i^1 - Y_i^0|D_i=1] \\
&=& E[Y_i^1|D_i=1] - E[Y_i^0|D_i=1] 
\end{array}
$${#eq-ATT}

Esta magnitud se llama **ATT**[^ATT] y se calcula de la misma forma que el **ATE** pero condicionando los $\delta_i$ al valor de $D_i$ igual a 1. De manera análoga definimos el efecto promedio pero para el grupo no tratado[^ATU]($D_i=0$)

[^ATT]: Del inglés *Average treatment effect for the treated*.
[^ATU]: Del inglés *Average treatment effect for the untreated*.

$$
\begin{array}
_ATU &=& E[\delta_i|D_i=0] \\
&=& E[Y_i^1 - Y_i^0|D_i=0] \\
&=& E[Y_i^1|D_i=0] - E[Y_i^0|D_i=0] 
\end{array}
$${#eq-ATU}

Ojo con confundir estos tres conceptos. Creo que el **ATE** es autoexplicativo, pero se suele confundir **ATT** y **ATU**. En el primer caso, estamos calculando la esperanza de los $\delta_i$ para los individuos pertenecientes al grupo tratamiento. Esto involucra tanto sus $Y^1_i$ como sus $Y^0_i$. Es una confusión común confundir estos efectos promedios con magnitudes no potenciales pero, como se observa de sus fórmulas, tanto estos últimos dos como el **ATE** no se pueden calcular en la práctica. En las secciones siguientes vamos a ver como, cumpliendo ciertas condiciones[^indep], podemos estimar el **ATE** a partir de los *outcomes* observables.

[^indep]: Spoiler: Asignación aleatoria de las unidades experimentales a los grupos.

## Diferencia de medias simple

¿Qué es lo que sí podemos observar? Una magnitud que a priori podríamos creer que va  aestar relacionada con el **ATE** y que podemos observar es la diferencia de medias entre los *outcomes* observados del grupo tratamiento y el grupo control. La vamos a llamar **SDO**[^SDO] y se calcula de la siguiente forma:

[^SDO]: Del inglés *simple difference in outcomes*.

$$
\begin{array}
_SDO &=& E[Y_i^1|D_i=1] - E[Y_i^0|D_i=0] \\
&=& \frac{1}{N_T} \sum_{i=1}^{N_T} (y_i|d_i=1) - \frac{1}{N_C} \sum_{i=1}^{N_C} (y_i|d_i=0)
\end{array}
$${#eq-SDO}

Donde $N_T$ y $N_C$ son la cantidad de individuos en el grupo tratamiento y control respectivamente (y $N_T + N_C = n$). Todo muy lindo, pero operemos un poquito para ver hasta que punto el **SDO** es un estimador insesgado del **ATE**. Empecemos escribiendo el **ATE** como una suma pesada del **ATT** y el **ATU**:

$$
\begin{array}
_ATE &=& \pi ATT + (1-\pi) ATU \\
&=& \pi E[Y_i^1|D_i=1] - \pi E[Y_i^0|D_i=1] + \\
& & (1-\pi) E[Y_i^1|D_i=0] - (1-\pi) E[Y_i^0|D_i=0] \\
&=& \bigl\{ \pi E[Y_i^1|D_i=1] + (1-\pi) E[Y_i^1|D_i=0] \bigl\} - \\
& & \bigl\{ \pi E[Y_i^0|D_i=1] + (1-\pi) E[Y_i^0|D_i=0] \bigl\}
\end{array}
$${#eq-sesgos}

Con $\pi = N_T/n$ y $1 - \pi = N_C/n$.

Operando con la @eq-sesgos podemos despejar la diferencia entre los *outcomes* observables (**SDO**) y ver cómo esta se realciona con el resto de las magnitudes definidas[^potential_outcomes-2].

[^potential_outcomes-2]: Pueden ver el despeje numérico en detalle en el capítulo 4 de [@cunningham2021causal].

$$
\begin{array}
_E[Y_i^1|D_i=1] - E[Y_i^0|D_i=0] &=& ATE \\
&+& ( E[Y_i^0|D_i=1] - E[Y_i^0|D_i=0] ) \\
&+& (1-\pi) (ATT - ATU)
\end{array}
$${#eq-sesgos}

Que podemos reescribir como:

$$
\begin{array}
_\underbrace{\frac{1}{N_T} \sum_{i=1}^{N_T} (y_i|d_i=1) - \frac{1}{N_C} \sum_{i=1}^{N_C} (y_i|d_i=0)}_\text{Diferencia de los outcomes} &=& \underbrace{ATE}_\text{Efecto promedio del tratamiento} \\
&+& \underbrace{( E[Y_i^0|D_i=1] - E[Y_i^0|D_i=0] )}_\text{Sesgo de selección} \\
&+& \underbrace{(1-\pi) (ATT - ATU)}_\text{Sesgo de efecto heterogéneo}
\end{array}
$$ {#eq-SDOdecomp}

Lo que puede verse en @eq-SDOdecomp es que si pudiéramos asegurar de alguna forma que los sesgos de selección y de efecto heterogéneo fueran cero, el **SDO** sería un buen estimador del **ATE** que es, al fin y al cabo, el efecto causal promedio que nos interesa en nuestro experimento.

## Independencia

La definición de independencia en el contexto de los *potential outcomes* es la siguiente:

$$
(Y^0, Y^1) \perp D
$$ Momento cerebrito, pensemos una poco qué quiere decir. Esto significa que la asignación de los participantes al grupo control o tratamiento ($D$) no depende de los *outcomes* potenciales de ese individuo.

Vamos a pensarlo con un ejemplo concreto. Imaginen que tenemos una grupo de participantes para poner a prueba una cirugía experimental como altenativa a un tratamiento médico establecido no quirúrgico. Si la asingación de individuos al grupo tratamiento la hace un médico en base a lo que cree que va a ser conveniente para él, por ejemplo, no asignando a pacientes de edad avanzada al grupo tratamiento por el riesgo asociado a una cirugía, o asignando a pacientes cuyo pronóstico con el método tradicional vea poco favorable al grupo control. En este caso, la asignación a un grupo **sí** depende de los posibles resultados, por lo tanto, no hay independencia. Si en lugar de eso tiráramos una moneda antes de recibir a cada paciente, podríamos de esa forma asegurar la independencia.

La independencia implica que se cumpla:

$$
\begin{array}
_E[Y^1|D=1] - E[Y^1|D=0] &=& 0 \\
E[Y^0|D=1] - E[Y^0|D=0] &=& 0
\end{array}
$$ {#eq-independencia}

Es decir, que la esperanza de los *outcomes* para los participantes que fueron asignados al grupo tratamiento como al grupo control serían iguales si pudieramos medirlos a ambos en "mundo tratamiento"[^potential_outcomes-3]. Y lo mismo pasaría si pudiéramos medirlos a ambos grupos en el "mundo control"\[\^indep\]. Ojo que esto no implica que la esperanza del *outcome* para tratamiento en los tratados sea igual a la esperanza para no tratamiento en los controles ($E[Y^1|D=1] - E[Y^0|D=0] = 0$) ni igual a la esperanza no tratamiento de los tratados ($E[Y^1|D=1] - E[Y^0|D=1] = 0$).

[^potential_outcomes-3]: Tengamos en cuenta que $E[Y^1|D=0]$ es un contrafáctico, ya que es el *outcome* habiendo sido expuesto al tratamiento pero de los individuos en el grupo control (de ahí la condicionalidad con $D=0$)

¿Qué implicancias tiene las igualdades presentadas en @eq-independencia en los sesgos que vimos en la ecuación @eq-sesgos? Empecemos por el sesgo de selección ($E[Y^0|D=1] + E[Y^0|D=0]$). Vemos que, deacuerdo a la primera línea de @eq-independencia ya nos dice que, de ser independiente la asignación del grupo experimental, este sesgo sería cero. Pensemos un poco. Lo que nos está diciendo la condición de independencia es que si ambos grupos fueran no tratados, ambos tendrían el mismo *outcome* lo que pareciera indicarnos que es razonable considerar nulo al sesgo de selección.

La relación del sesgo de efecto heterogéneo ($(1-\pi) (ATT - ATU)$) con la independencia es un poquito más difícil de demostrar. Olvidémonos del $(1-\pi)$ de momento. Reescribamos los efectos **ATT** y **ATU**:

$$
\begin{array}
_ATT &=& E[Y^1|D=1] - E[Y^0|D=1] \\
ATU &=& E[Y^1|D=0] - E[Y^0|D=0] 
\end{array}
$$

Y ahora restemos ambos términos:

$$
\begin{array}
_ATT - ATU &=& E[Y^1|D=1] - E[Y^0|D=1] - ( E[Y^1|D=0] - E[Y^0|D=0] )\\
&=& \bigl\{ E[Y^1|D=1] - E[Y^1|D=0] \bigl\} + \bigl\{ E[Y^0|D=0] - E[Y^0|D=1] \bigl\} 
\end{array}
$$ {#eq-sesgohet}

Reescrito de esta forma podemos ver los dos primero términos de @eq-sesgohet se hacen cero por la rpimero línea de @eq-independencia, y los últimos dos se hacen cero por la segunda.

Finalmente, demostramos que si hay independencia en la asignación de los grupos, la diferencia de las medias entre el grupo tratado y el control es un buen estimador del **ATE**.
